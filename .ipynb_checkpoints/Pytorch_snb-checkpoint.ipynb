{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_TKdrdfT0KN"
   },
   "source": [
    "klasy na podstawie ceny\n",
    "0-100 tys -> 0\n",
    "100-350 -> 1\n",
    "350+ ->2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iBy28btzhWeC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "class MyNetBN2(nn.Module):\n",
    "  \n",
    "    def __init__(self, num_inputs, num_hidden, num_hidden2,num_outputs):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act1 =nn.LeakyReLU()\n",
    "        self.lin2 =nn.Linear(num_hidden, num_hidden2)\n",
    "        self.act2 =nn.LeakyReLU()\n",
    "        self.lin3 =nn.Linear(num_hidden2, num_outputs)\n",
    "        self.act3=nn.Sigmoid()\n",
    "             \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.act3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Uajb2YEfg-LP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "txt = open(r'C:\\Users\\karol\\Desktop\\SNB\\Statlog_(Heart)_MLR\\heart.dat')\n",
    "txt_list = [line.replace('\\n','').split(' ') for line in txt.readlines()]\n",
    "df = pd.DataFrame(txt_list, columns=['age','sex','chestpaintype','resting blood pressure', 'serum cholestoral', 'fasting blood sugar', 'restingelectrocardiographicresults', 'maximum heart rate achieved', 'exercise induced angina', 'oldpeak', 'slope of the peak exercise', 'number of major vessels', 'thal', 'heartdisease'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a8qhnzrDf3oP"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder #onehot preprocessing\n",
    "from numpy.core.multiarray import concatenate\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "feature_arry = ohe.fit_transform(df[[\"chestpaintype\",\"restingelectrocardiographicresults\",\"thal\"]]).toarray()\n",
    "\n",
    "\n",
    "#feature_labels = ohe.categories_\n",
    "#feature_labels = np.array(concatenate(feature_labels))\n",
    "\n",
    "feature_labels=np.array([\"chestpaintype_1\",\"chestpaintype_2\",\"chestpaintype_3\",\"chestpaintype_4\",\"restingelectrocardiographicresults_1\",\"restingelectrocardiographicresults_2\",\"restingelectrocardiographicresults_3\",\"thal_1\",\"thal_2\",\"thal_3\"])\n",
    "\n",
    "features = pd.DataFrame(feature_arry, columns = feature_labels)\n",
    "df_new = pd.concat([df[['age','sex','resting blood pressure', 'serum cholestoral', 'fasting blood sugar', 'maximum heart rate achieved', 'exercise induced angina', 'oldpeak', 'slope of the peak exercise', 'number of major vessels', 'heartdisease']], features], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TyxEChy5f34l"
   },
   "outputs": [],
   "source": [
    "train=df_new.sample(frac=0.8,random_state=1) #normalizacja, nie sprawdzałem jeszcze czy całe działa\n",
    "test=df_new.drop(train.index)\n",
    "\n",
    "train.describe()\n",
    "\n",
    "test=test.astype(float)\n",
    "train=train.astype(float)\n",
    "\n",
    "heartdisease=train.heartdisease\n",
    "train=train.drop('heartdisease',axis=1)\n",
    "heartdisease_test=test.heartdisease\n",
    "test=test.drop('heartdisease',axis=1)\n",
    "\n",
    "test=test.astype(float)\n",
    "train=train.astype(float)\n",
    "minimum=train.min()\n",
    "maximum=train.max()\n",
    "train=((train-minimum)/(maximum-minimum))\n",
    "test=((test-minimum)/(maximum-minimum))\n",
    "\n",
    "train['heartdisease']=heartdisease-1\n",
    "test['heartdisease']=heartdisease_test-1\n",
    "test=test.astype(float)\n",
    "train=train.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CZ1QlHGOX90z"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "train_input=train.drop('heartdisease',axis=1)\n",
    "\n",
    "train_output=train['heartdisease']\n",
    "\n",
    "test_input=test.drop('heartdisease',axis=1)\n",
    "test_output=test['heartdisease']\n",
    "\n",
    "\n",
    "train_dataset = data.TensorDataset(torch.from_numpy(train_input.values),torch.from_numpy(train_output.values)) #zrobić na indeksach, w poprzednim zadaniu przy normalizacji ułożyło kolumny alfabetycznie\n",
    "test_dataset= data.TensorDataset(torch.from_numpy(test_input.values),torch.from_numpy(test_output.values))\n",
    "\n",
    "train_data_loader=DataLoader(train_dataset,batch_size=32,shuffle=True,drop_last=True)\n",
    "test_data_loader=DataLoader(test_dataset,batch_size=1,shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOt0JFWiZISu"
   },
   "outputs": [],
   "source": [
    "def training_two(lay_one,lay_two):\n",
    "  max_epochs = 350\n",
    "\n",
    "  model1 = MyNetBN2(num_inputs=20, num_hidden=lay_one,num_hidden2=lay_two ,num_outputs=1)\n",
    "  optimizer1=torch.optim.Adam(model1.parameters())\n",
    "  loss_fn = nn.BCELoss()\n",
    "\n",
    "\n",
    "  model1.train()\n",
    "  loss_arr1 = []\n",
    "  tpa,tna,fpa,fna=[],[],[],[]\n",
    "\n",
    "  for epoch in range(max_epochs):\n",
    "      for inputs, labels in train_data_loader:\n",
    "\n",
    "          inputs = inputs.to(torch.float32)\n",
    "          labels = labels.to(torch.float32)\n",
    "          # training steps for normal model\n",
    "\n",
    "          optimizer1.zero_grad()\n",
    "\n",
    "          outputs1 = model1(inputs).squeeze()\n",
    "\n",
    "          loss1 = loss_fn(outputs1, labels)\n",
    "\n",
    "          loss1.backward()\n",
    "        \n",
    "          optimizer1.step()\n",
    "       \n",
    "        \n",
    "      loss_arr1.append(loss1.item())\n",
    "      tp,tn,fp,fn = evaluate(model1,\"abc\")\n",
    "      tpa.append(tp)\n",
    "      tna.append(tn)\n",
    "      fpa.append(fp)\n",
    "      fna.append(fn)\n",
    "  \n",
    "  length = np.arange(len(tpa))\n",
    "  plt.plot(loss_arr1,'g')\n",
    "#   plt.plot(length,tpa,\"g\")\n",
    "#   plt.plot(length,tna,\"r\")\n",
    "#   plt.plot(length,fpa,\"b\")\n",
    "#   plt.plot(length,fna,\"m\")\n",
    "  plt.show() \n",
    "\n",
    "def evaluate(mod,nn_neurons):\n",
    "  mod.eval() \n",
    "  pre_preds,true_preds, num_preds,error = 0., 0., 0., 0.\n",
    "  tp, tn, fp, fn = 0,0,0,0\n",
    "  with torch.no_grad(): \n",
    "      for data_inputs, data_labels in test_data_loader:\n",
    "        \n",
    "          data_inputs, data_labels = data_inputs.to(torch.float32), data_labels.to(torch.float32)\n",
    "          preds = mod(data_inputs)\n",
    "\n",
    "\n",
    "          preds = preds.squeeze(dim=1)\n",
    "          pred_labels = (torch.round(preds).int()).long() \n",
    "          error=+abs(preds-data_labels)\n",
    "          pre_pred_labels=abs(preds-data_labels)\n",
    "      \n",
    "          true_preds += (pred_labels == data_labels).sum()\n",
    "          if(pred_labels == data_labels):\n",
    "                if(data_labels == 1):\n",
    "                    tp+=1\n",
    "                else:\n",
    "                    tn+=1\n",
    "          else:\n",
    "                if(data_labels == 1):\n",
    "                    fn+=1\n",
    "                else:\n",
    "                    fp+=1\n",
    "                    \n",
    "          pre_preds += (pre_pred_labels <1).sum()\n",
    "          num_preds += data_labels.shape[0]\n",
    "  return tp,tn,fp,fn\n",
    "\n",
    "\n",
    "    \n",
    "import csv\n",
    "\n",
    "training_two(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
